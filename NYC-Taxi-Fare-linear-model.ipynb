{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# This is a project using linear model for the New York City Taxi Fare Prediction Playground Competition \r\n",
    "Here we'll use several features like the travel vector from the taxi's pickup location to dropoff location which predicts the `fare_amount` of each ride.\r\n",
    "\r\n",
    "`pandas` and `numpy` are libraries used for most of the critical work instead of `sklearn` or `statsmodels`"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial Python environment setup...\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # CSV file I/O (e.g. pd.read_csv)\n",
    "import os # reading the input files we have access to"
   ]
  },
  {
   "source": [
    "### Setup training data\n",
    "Let's read our training data, but since the dataset consists of around 55M rows let's just take a portion the system kernel can handle for now"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df =  pd.read_csv('../input/train.csv', nrows = 10_000_000)\n",
    "train_df.dtypes"
   ]
  },
  {
   "source": [
    "Let's compute the travel vectors between longitude and latitude coordinates"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given a dataframe, add two new features 'abs_diff_longitude' and\n",
    "# 'abs_diff_latitude' reprensenting the \"Manhattan vector\" from\n",
    "# the pickup location to the dropoff location.\n",
    "def add_travel_vector_features(df):\n",
    "    df['abs_diff_longitude'] = (df.dropoff_longitude - df.pickup_longitude).abs()\n",
    "    df['abs_diff_latitude'] = (df.dropoff_latitude - df.pickup_latitude).abs()\n",
    "\n",
    "add_travel_vector_features(train_df)"
   ]
  },
  {
   "source": [
    "### Explore and prune outliers\n",
    "First let's see if there are any `NaN`s in the dataset."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_df.isnull().sum())"
   ]
  },
  {
   "source": [
    "There are a small amount, so let's remove them from the dataset."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Old size: %d' % len(train_df))\n",
    "train_df = train_df.dropna(how = 'any', axis = 'rows')\n",
    "print('New size: %d' % len(train_df))"
   ]
  },
  {
   "source": [
    "Now let's plot a subset of our travel vector features to see its distribution."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot = train_df.iloc[:2000].plot.scatter('abs_diff_longitude', 'abs_diff_latitude')"
   ]
  },
  {
   "source": [
    "Since most of the data regards only one city and 1Â° of latitude is appriximatively equivalent to 111 kilometers, we can safely say that the indivuals on the right with values superior than 5 are outliers and we can remove them from our dataset"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Old size: %d' % len(train_df))\n",
    "train_df = train_df[(train_df.abs_diff_longitude < 5.0) & (train_df.abs_diff_latitude < 5.0)]\n",
    "print('New size: %d' % len(train_df))"
   ]
  },
  {
   "source": [
    "### Train our model\n",
    "Our model will take the form $X \\cdot w = y$ where $X$ is a matrix of input features, and $y$ is a column of the target variable, `fare_amount`, for each row. The weight column $w$ is what we will \"learn\".\n",
    "\n",
    "First let's setup our input matrix $X$ and target column $y$ from our training set.  The matrix $X$ should consist of the two GPS coordinate differences, number of passengers plus a fourth term of 1 to allow the model to learn a constant bias term.  The column $y$ should consist of the target `fare_amount` values."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct and return an Nx3 input matrix for our linear model\n",
    "# using the travel vector, plus a 1.0 for a constant bias term.\n",
    "def get_input_matrix(df):\n",
    "    return np.column_stack((df.abs_diff_longitude, df.abs_diff_latitude, df.passenger_count ,np.ones(len(df))))\n",
    "\n",
    "train_X = get_input_matrix(train_df)\n",
    "train_y = np.array(train_df['fare_amount'])\n",
    "\n",
    "print(train_X.shape)\n",
    "print(train_y.shape)"
   ]
  },
  {
   "source": [
    "Now let's use `numpy`'s `lstsq` library function to find the optimal weight column $w$."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The lstsq function returns several things, and we only care about the actual weight vector w.\n",
    "(w, _, _, _) = np.linalg.lstsq(train_X, train_y, rcond = None)\n",
    "print(w)"
   ]
  },
  {
   "source": [
    "These weights pass a quick sanity check, since we'd expect the first two values -- the weights for the absolute longitude and latitude differences -- to be positive, as more distance should imply a higher fare, and we'd expect the bias term to loosely represent the cost of a very short ride.\n",
    "\n",
    "Sidenote:  we can actually calculate the weight column $w$ directly using the [Ordinary Least Squares](https://en.wikipedia.org/wiki/Ordinary_least_squares) method:\n",
    "$w = (X^T \\cdot X)^{-1} \\cdot X^T \\cdot y$"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_OLS = np.matmul(np.matmul(np.linalg.inv(np.matmul(train_X.T, train_X)), train_X.T), train_y)\n",
    "print(w_OLS)"
   ]
  },
  {
   "source": [
    "### Make predictions on the test set\n",
    "Now let's load up our test inputs and predict the `fare_amount`s for them using our learned weights!"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('../input/test.csv')\n",
    "test_df.dtypes"
   ]
  },
  {
   "source": [
    "# Reuse the above helper functions to add our features and generate the input matrix.\n",
    "add_travel_vector_features(test_df)\n",
    "test_X = get_input_matrix(test_df)\n",
    "# Predict fare_amount on the test set using our model (w) trained on the training set.\n",
    "test_y_predictions = np.matmul(test_X, w).round(decimals = 2)\n",
    "\n",
    "# Write the predictions to a CSV file which we can submit to the competition.\n",
    "submission = pd.DataFrame(\n",
    "    {'key': test_df.key, 'fare_amount': test_y_predictions},\n",
    "    columns = ['key', 'fare_amount'])\n",
    "submission.to_csv('submission.csv', index = False)\n",
    "\n",
    "print(os.listdir('.'))"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "source": [
    "## Ideas for Improvement\n",
    "The output here will score an RMSE of less than $5, better can be donehere!  Here are some suggestions:\n",
    "\n",
    "* Use the datetime to capture seasonality and/or time of the day that could depict traffic density and therefore influence the `fare_amounts` & improve results\n",
    "* Use absolute starting and drop off points as the starting location itself could affect the travel time & thus could be useful\n",
    "* Use a more complex model (non-linear for example) could approach more the reality\n",
    "* Construct more useful features ...\n",
    "* Use the entire dataset"
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}